{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "addition_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjamQHI2p/HXGQjPCheVG7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidhant-guliani/Deep-learning-projects/blob/master/addition_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkn_nK_NMsC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import os\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Sequential\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GZczHbsiiNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj1yqZV4ij_A",
        "colab_type": "text"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byFFdXASsMQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LIMIT = 50000\n",
        "MAX_DIGITS = 3\n",
        "MAX_LEN_QUEST = MAX_DIGITS + MAX_DIGITS + 1 \n",
        "REVERSE = False\n",
        "# +1 for the \"+\" sign"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7zHoxFoolpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class char_DataGen:\n",
        "  \"\"\" Given set of characters\n",
        "  + one_hot_encoder \n",
        "  + one_hot_decoder reverses converts the \n",
        "  \"\"\"\n",
        "  def __init__(self, char):\n",
        "    self.char = sorted(set(char))\n",
        "    self.char_table = dict((c, i) for i, c in enumerate(self.char))\n",
        "    self.rev_char_table = dict((i, c) for i, c in enumerate(self.char))\n",
        "\n",
        "  def one_hot_encoder(self, q, ans= False):\n",
        "    \"\"\" one hot encofer for a string\n",
        "    arguments:\n",
        "    q: string that you want to hot encode\n",
        "    \"\"\" \n",
        "    x = np.zeros((len(q), len(self.char)))\n",
        "    for i, c in enumerate(q):\n",
        "      x[i, self.char_table[c]] = 1\n",
        "    return x\n",
        "\n",
        "  def decoder(self, x, calc_argmax = True):\n",
        "    \"\"\"Decode the given vector or 2D array to their character output.\n",
        "        # Arguments\n",
        "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
        "                or a vector of character indices (used with `calc_argmax=False`).\n",
        "            calc_argmax: Whether to find the character index with maximum\n",
        "                probability, defaults to `True`.\n",
        "        \"\"\"\n",
        "    if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "    return \"\".join(self.rev_char_table[x] for x in x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubDHl2mMr3Ga",
        "colab_type": "text"
      },
      "source": [
        "step1: We are generating queston and the expected answers. make sure you follow the rules while creating the datasets. Rules:\n",
        "1. \n",
        "\n",
        "step2: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzG0MwrKs8oy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3e3dc74-a5ee-40b7-97cd-993eeb9fcb82"
      },
      "source": [
        "questions = []\n",
        "answers = []\n",
        "seen = set()\n",
        "\n",
        "chars = \"0123456789+ \"\n",
        "\n",
        "while len(questions) < MAX_LIMIT:\n",
        "  f = lambda: int(\"\".join(np.random.choice(list(\"0123456789\"))\n",
        "                  for i in range(np.random.randint(1,MAX_DIGITS+1))))\n",
        "  \n",
        "  a, b = f(), f()\n",
        "  # skip anycase which is already in the list\n",
        "  #hence we are storing the combination in seen\n",
        "  combo = tuple(sorted((a,b)))\n",
        "  if combo in seen:\n",
        "    continue\n",
        "  seen.add(combo)\n",
        "  quest = \"{}+{}\".format(a, b)\n",
        "  # padding for the question\n",
        "  questn = quest + \" \"*(MAX_LEN_QUEST - len(quest))\n",
        "  ans = str(a+ b)\n",
        "  # the answer should be of length 4 so applying padding\n",
        "  ans += \" \"*(1+MAX_DIGITS - len(ans))\n",
        "\n",
        "  questions.append(questn)\n",
        "  answers.append(ans)\n",
        "\n",
        "print(\"question shape\", len(questions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "question shape 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQFmd3wakTDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_data = np.zeros((MAX_LIMIT, MAX_LEN_QUEST, len(chars)))\n",
        "y_data = np.zeros((MAX_LIMIT, MAX_DIGITS+1, len(chars)))\n",
        "\n",
        "# initiating an object for the class\n",
        "datagen = char_DataGen(chars)\n",
        "\n",
        "for i, q in enumerate(questions):\n",
        "  x_data[i] = datagen.one_hot_encoder(q)\n",
        "\n",
        "for i, q in enumerate(answers):\n",
        "  y_data[i] = datagen.one_hot_encoder(q)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdTY3gWjweFt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2cb55ac6-f232-4121-aec4-80426c359cc2"
      },
      "source": [
        "print(x_data.shape)\n",
        "print(y_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 7, 12)\n",
            "(50000, 4, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO4cor7ZwMZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpnOLqgfwzGg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "7a42c3b3-4e2b-4fb1-80e9-b9ae4e000dc4"
      },
      "source": [
        "model = Sequential()\n",
        "#\n",
        "model.add(layers.LSTM(128, input_shape=(MAX_LEN_QUEST, len(chars))))\n",
        "model.add (layers.RepeatVector(MAX_DIGITS+1))\n",
        "model.add(layers.LSTM(128,return_sequences= True))\n",
        "model.add(layers.Dense(len(chars), activation = \"softmax\"))\n",
        "model.compile(loss= \"categorical_crossentropy\", optimizer=\"adam\", metrics = [\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 128)               72192     \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 4, 128)            131584    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4, 12)             1548      \n",
            "=================================================================\n",
            "Total params: 205,324\n",
            "Trainable params: 205,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqVOrPVjw2C9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "0457b0a8-cc89-42ec-e127-0a80d7510e59"
      },
      "source": [
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size= 32,\n",
        "          epochs = 15,\n",
        "          validation_data= (x_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 1.7907 - accuracy: 0.3475 - val_loss: 1.6266 - val_accuracy: 0.3976\n",
            "Epoch 2/15\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 1.4396 - accuracy: 0.4596 - val_loss: 1.2971 - val_accuracy: 0.5119\n",
            "Epoch 3/15\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.2188 - accuracy: 0.5407 - val_loss: 1.1562 - val_accuracy: 0.5602\n",
            "Epoch 4/15\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 1.0769 - accuracy: 0.5898 - val_loss: 1.0306 - val_accuracy: 0.5998\n",
            "Epoch 5/15\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.9584 - accuracy: 0.6364 - val_loss: 0.9166 - val_accuracy: 0.6528\n",
            "Epoch 6/15\n",
            "1250/1250 [==============================] - 21s 16ms/step - loss: 0.8665 - accuracy: 0.6712 - val_loss: 0.8409 - val_accuracy: 0.6749\n",
            "Epoch 7/15\n",
            "1250/1250 [==============================] - 21s 16ms/step - loss: 0.7388 - accuracy: 0.7180 - val_loss: 0.6679 - val_accuracy: 0.7407\n",
            "Epoch 8/15\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.5469 - accuracy: 0.7996 - val_loss: 0.4776 - val_accuracy: 0.8263\n",
            "Epoch 9/15\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.3906 - accuracy: 0.8692 - val_loss: 0.3189 - val_accuracy: 0.9003\n",
            "Epoch 10/15\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.2781 - accuracy: 0.9134 - val_loss: 0.2363 - val_accuracy: 0.9293\n",
            "Epoch 11/15\n",
            "1250/1250 [==============================] - 22s 18ms/step - loss: 0.1986 - accuracy: 0.9431 - val_loss: 0.1808 - val_accuracy: 0.9480\n",
            "Epoch 12/15\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.1508 - accuracy: 0.9585 - val_loss: 0.1453 - val_accuracy: 0.9573\n",
            "Epoch 13/15\n",
            "1250/1250 [==============================] - 20s 16ms/step - loss: 0.1193 - accuracy: 0.9673 - val_loss: 0.1024 - val_accuracy: 0.9730\n",
            "Epoch 14/15\n",
            "1250/1250 [==============================] - 21s 16ms/step - loss: 0.0909 - accuracy: 0.9764 - val_loss: 0.1147 - val_accuracy: 0.9651\n",
            "Epoch 15/15\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 0.0847 - accuracy: 0.9769 - val_loss: 0.1044 - val_accuracy: 0.9666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3440696828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0fDFtm8qqTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f0e100ff-c492-4587-9c85-52b00e8cb27e"
      },
      "source": [
        "# selecting 10 samples from the validation set so taht we can visualise the errors\n",
        "for i in range(10):\n",
        "  ind = np.random.randint(0, len(x_val))\n",
        "  rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "  preds = np.argmax(model.predict(rowx), axis=-1)\n",
        "  q = datagen.decoder(rowx[0])\n",
        "  a = datagen.decoder(rowy[0])\n",
        "  guess = datagen.decoder(preds[0], calc_argmax= False)\n",
        "  print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
        "  print(\"T\", a, end=\" \")\n",
        "  if a == guess:\n",
        "      print(\"☑ \" + guess)\n",
        "  else:\n",
        "      print(\"☒ \" + guess)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q 464+23  T 487  ☑ 487 \n",
            "Q 396+821 T 1217 ☑ 1217\n",
            "Q 360+340 T 700  ☒ 701 \n",
            "Q 575+9   T 584  ☑ 584 \n",
            "Q 6+72    T 78   ☑ 78  \n",
            "Q 21+44   T 65   ☑ 65  \n",
            "Q 9+4     T 13   ☑ 13  \n",
            "Q 45+97   T 142  ☑ 142 \n",
            "Q 3+810   T 813  ☑ 813 \n",
            "Q 731+607 T 1338 ☑ 1338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G59yM7yPYf_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "623ecd0d-1b1c-4121-f77d-2cd3fee381c7"
      },
      "source": [
        "print(np.argmax(model.predict(rowx), axis = -1))\n",
        "print(model.predict(rowx)[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10  9 10  0]]\n",
            "[[7.43903376e-12 5.94585700e-11 3.83026553e-08 2.34667095e-11\n",
            "  8.31297357e-12 2.33038046e-12 6.76173188e-14 2.79715530e-12\n",
            "  5.49028698e-08 9.33744665e-03 9.90556479e-01 1.06015796e-04]\n",
            " [7.28135271e-13 1.32997929e-13 1.20561727e-10 5.59233175e-14\n",
            "  1.22611206e-15 3.75090457e-15 2.78114933e-14 4.91843233e-10\n",
            "  1.97083704e-04 8.96950245e-01 1.02849334e-01 3.33244384e-06]\n",
            " [3.89028454e-09 3.65312351e-15 1.16237953e-08 4.21112382e-15\n",
            "  1.69217711e-17 9.92142016e-18 3.25851415e-15 2.02662175e-11\n",
            "  4.87718594e-08 4.38124378e-04 9.95148718e-01 4.41303663e-03]\n",
            " [9.99590099e-01 6.23125141e-14 8.94967656e-09 3.03646234e-15\n",
            "  8.72050965e-16 1.55507771e-17 6.07662072e-16 1.37787318e-12\n",
            "  1.41058298e-09 1.08745271e-05 3.51555471e-04 4.74809058e-05]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCt6SRWUqwBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPtsnHa9X-Es",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "148275f2-5fe0-43c8-9eba-1dc3e33d4002"
      },
      "source": [
        "for i, q in enumerate(questions[:10]):\n",
        "  print(questions[i], answers[i])\n",
        "  aa = datagen.one_hot_encoder(q)\n",
        "  bb = datagen.one_hot_encoder(answers[i])\n",
        "  print(aa)\n",
        "  print(bb)\n",
        "  print(\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41+76   117 \n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            " \n",
            "52+60   112 \n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            " \n",
            "2+70    72  \n",
            "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            " \n",
            "786+6   792 \n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            " \n",
            "0+41    41  \n",
            "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            " \n",
            "8+7     15  \n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            " \n",
            "888+358 1246\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
            " \n",
            "55+598  653 \n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            " \n",
            "24+9    33  \n",
            "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            " \n",
            "6+9     15  \n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT5TyBa7lq84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "445663f8-3ad4-4843-ce0d-dfc712229434"
      },
      "source": [
        "ind = np.random.randint(0, len(x_val))\n",
        "rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "preds = np.argmax(model.predict(rowx), axis=-1)\n",
        "q = datagen.decoder(rowx[0])\n",
        "a = datagen.decoder(rowy[0])\n",
        "guess = datagen.decoder(preds[0], calc_argmax= False)\n",
        "print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
        "print(\"T\", a, end=\" \")\n",
        "if a == guess:\n",
        "    print(\"☑ \" + guess)\n",
        "else:\n",
        "    print(\"☒ \" + guess)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q 481+819 T 1102 ☑ 1102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnc_Sm4x1eaT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "70b99dea-feca-4afb-d40c-5e619019819a"
      },
      "source": [
        "print(x_val[np.array([ind])])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8_nGeOl1pSU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f059a62b-c717-4f8c-90f8-d7997834ae61"
      },
      "source": [
        "print(rowx[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bpij-fmH19Gt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a042a976-ab9f-4e64-d0de-686f903b9e62"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'481+819'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miZdYxLp2Mbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}